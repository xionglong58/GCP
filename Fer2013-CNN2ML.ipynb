{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "import os,cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_conv4', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_conv4', 'block4_pool', 'block5_conv1', 'block5_conv2', 'block5_conv3']\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(weights='imagenet',include_top=False)\n",
    "# 获取各层的输出：\n",
    "layer_outputs = [layer.output for layer in base_model.layers[2:20]]\n",
    "# 获取各层的名称：\n",
    "layer_names = []\n",
    "for layer in base_model.layers[2:20]:\n",
    "    layer_names.append(layer.name)\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./fer2013.csv',header=0,encoding=\"utf-8\")\n",
    "features=df.iloc[:,:]['pixels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(df.iloc[:,:]['emotion']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 48, 48, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=[]\n",
    "for feature in features:\n",
    "    img=np.array(feature.split(\" \")).astype('float32').reshape(48,48)/255\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    result.append(img)\n",
    "features=np.array(result)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conj_martix(martix):\n",
    "    result=[]\n",
    "    width=martix.shape[0]\n",
    "    height=martix.shape[1]\n",
    "    nums=martix.shape[2]\n",
    "    for num in range(nums):\n",
    "        result.append(martix[:,:,num].flatten())\n",
    "    return result\n",
    "\n",
    "from numpy import nanmean\n",
    "\n",
    "def downsample(myarr,factor,estimator=nanmean):\n",
    "    \"\"\"\n",
    "    Downsample a 2D array by averaging over *factor* pixels in each axis.\n",
    "    Crops upper edge if the shape is not a multiple of factor.\n",
    "    This code is pure np and should be fast.\n",
    "    keywords:\n",
    "        estimator - default to mean.  You can downsample by summing or\n",
    "            something else if you want a different estimator\n",
    "            (e.g., downsampling error: you want to sum & divide by sqrt(n))\n",
    "    \"\"\"\n",
    "    ys,xs = myarr.shape\n",
    "    crarr = myarr[:ys-(ys % int(factor)),:xs-(xs % int(factor))]\n",
    "    dsarr = estimator( np.concatenate([[crarr[i::factor,j::factor] \n",
    "        for i in range(factor)] \n",
    "        for j in range(factor)]), axis=0)\n",
    "    return dsarr\n",
    "\n",
    "def upper_gram(metrix):\n",
    "    features=[]\n",
    "    gram_len=metrix.shape[1]\n",
    "    for row in range(gram_len):\n",
    "        for clo in range(gram_len):\n",
    "            clos=clo+row\n",
    "            if(clos>gram_len-1):\n",
    "                break\n",
    "            features.append((metrix[row][row+clo]))\n",
    "    return np.array(features)\n",
    "\n",
    "def get_features(origin_features,layers):\n",
    "    features_mertix=[]\n",
    "    for index in range(origin_features.shape[0]):\n",
    "        cnn_featues=model.predict(origin_features[index:index+1,:,:,:])\n",
    "        layer_features=cnn_featues[layers][0]#获取第三层的输出\n",
    "        conj_mertix=np.array(conj_martix(layer_features))#拼接矩阵\n",
    "        gram_metrix=np.dot(conj_mertix, conj_mertix.T)#计算 gram 矩阵`\n",
    "        feature=upper_gram(gram_metrix)#取 gram 矩阵的上半区\n",
    "        features_mertix.append(feature)\n",
    "    return np.array(features_mertix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=get_features(features,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "knn = KNN(n_neighbors=1)\n",
    "scores = cross_val_score(knn, features, labels, cv=10)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "scores = cross_val_score(rf, features, labels, cv=10)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.to_csv('./fer2013-features-one-vec.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_conv4', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_conv4', 'block4_pool', 'block5_conv1', 'block5_conv2', 'block5_conv3']\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(weights='imagenet',include_top=False)\n",
    "# 获取各层的输出：\n",
    "layer_outputs = [layer.output for layer in base_model.layers[2:20]]\n",
    "# 获取各层的名称：\n",
    "layer_names = []\n",
    "for layer in base_model.layers[2:20]:\n",
    "    layer_names.append(layer.name)\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=layer_outputs)\n",
    "# 将前面的图片数据x，输入到model中，得到各层的激活值activations：\n",
    "activations = model.predict(features[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# for activation,layer_name in zip(activations[3:4],layer_names[3:4]):\n",
    "#     h = activation.shape[1]\n",
    "#     w = activation.shape[2]\n",
    "#     num_channels = activation.shape[3]\n",
    "#     cols = 3\n",
    "#     rows = 1\n",
    "#     img_grid = np.zeros((h*rows,w*cols))\n",
    "\n",
    "#     for c in range(3):\n",
    "#         f_r = math.ceil((c+1)/cols)\n",
    "#         f_c = (c+1)if f_r==1 else (c+1-(f_r-1)*cols)\n",
    "#         img_grid[(f_r-1)*h:f_r*h,(f_c-1)*w:f_c*w ] = activation[0,:,:,c]\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(25,25))\n",
    "#     plt.imshow(img_grid, aspect='equal',cmap='viridis')\n",
    "#     plt.grid(False)\n",
    "#     plt.title(layer_name,fontsize=16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "filename = './e7.jpg'\n",
    "img = cv2.imread(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
